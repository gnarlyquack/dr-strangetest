TODO
====

This file lists all tasks required for the next release. Items that might be
desirable for future releases may be listed at the bottom of the file.


Release
-------
-   Review test suite

-   Niggles to test/check:

    -   What happens if we try to tokenize an empty file?

    -   Do we properly handle directories whose name matches against file name
        patterns?

    -   Do we properly handle traversing towards a target that may have a
        potentially ambiguous directory name in the path? E.g., the target is
        in "tests/test_foobar/test_target.php" and the test suite also has the
        directory "tests/test_foo" (which may or may not also include a file
        "test_target.php")

    -   Do we not discover/traverse symbolic links?

    -   Do we handle traversing multiple times to a directory, file, etc. that
        had a setup error?

    -   (Directory) setup errors when there are targets

    -   Running targets that are a directory or a file that is parameterized
        with multiple argument lists, and/or in a directory hierarchy where
        one or more directories in the hierarchy are parameterized with
        multiple argument lists

-   Targets:

    -   find_class_target: don't use 'method_exists' to check if a target
        exists since this will cause non-test methods to be found as targets

    -   Allow namespaces for user-provided function and class targets to be
        automatically discovered so they don't need to be specified on the
        command line. This will probably require caching the list of declared
        namespaces within a file test

    -   Only user-provided targets need to be validated against discovered
        test names and this validation only needs to happen once. Targets
        built from dependencies should never need to be checked since they
        should always be valid, we should just be able to run them.

    -   Show a notice when duplicate user-provided targets are removed?

    -   Currently, user-provided class and function target declarations may be
        ignored if it's trivially determined that they're duplicates (e.g., we
        know we're already testing the entire file they're in). However, that
        means potentially-invalid target declarations won't cause an error. We
        may want to parse and validate all target declarations and report (and
        exit on) any errors. Although, a valid target declaration may still
        contain invalid targets, e.g., a non-existent identifier or a non-test
        identifier. These won't cause an error either since identifiers aren't
        validated until source files are parsed, by which time we've discarded
        any duplicate targets. Unless we want to hold them for validation?

    -   Class and function targets should be found without regard to case
        since PHP identifiers are case-insensitive. Presumably, this isn't an
        issue with paths since we're validating all user-provided paths with
        realpath()?

    -   Actually, the '--path=' specifier isn't necessary because any valid
        test path needs to start with 'test'(?)

-   Fix run names so that they don't have to start with a space

-   Cleanup parameters to setup(), teardown(), run() test methods

-   Add support for config files(?)

-   Implement additional CLI options(?)
    -   specify a config file
    -   enable/disable autoloading, and specify an autoloader file location?

-   Ensure we're UTF-8 conformant
    https://www.php.net/manual/en/migration71.windows-support.php#migration71.windows-support.long-and-utf8-path

-   Replace switches with if statements (to enforce strict comparison)

-   Diffs and formatting

    -   Cache LCS matrices so they don't need to be recalculated when
        generating the diff

    -   Split up formatting and diff (and perhaps additional "utility"
        functions) into separate files

    -   Ensure that values formatted in whole by format_variable() match
        how values are formatted when individual elements are diffed

    -   By default, don't treat numerical array keys as significant when
        comparing arrays. This can give us cleaner diffs, since an insert or
        deletion won't cause all the subsequent, reindexed elements to show as
        having been changed. The user should be able to override this so that
        keys are always considered significant

    -   When formatting array and class "headers", it seems we could have a
        non-compact diff if both the keys of the header and initial values are
        different:
            - 1 => array(
            + 2 => array(
            -   1 => 'foo',
            +   1 => 'bar',
        Is this something we want to try to "fix"?

    -   If the only difference between two composite values is their key, then
        we only need to diff the first line of each and can then copy the rest

-   Do we want/need to implement a UserError exception? E.g., we could throw
    an error from arglists() or from the ArgumentLists constructor if the
    argument is not an iterable, however the resulting error backtrace will
    originate from easytest code. A UserError would need to remove calls
    within EasyTest from the generated backtrace (like Failure and Skip do)

-   Any event that is logged using a string as the reason (as opposed to using
    an exception as the reason) will not have a backtrace identifying the
    source file name and line number. To the extent that it's possible, we
    probably want to always log an event using an exception as the reason.

-   Should we strip assert() calls (and potentially other debug activity) when
    building the phar? Since easytest requires assertions to be enabled, they
    will always be executed even though we would never expect them to trigger
    in a production release. If so, then we probably want to allow the phar
    version to be installable with Composer (a la psalm/phar, for example)

-   The comparison assertions ('<', '<=', '>', '>=') can operate
    (successfully) on (some) composite values. What implications does this
    have on formatting failure messages?
    https://www.php.net/manual/en/language.operators.comparison.php

-   Dependencies:

    -   Do we handle declaring a dependency on one's self?

    -   We need to ensure a run name can never clobber the "cumulative" result
        of a test, which it currently can if the name is an empty string

    -   Names given to Context::depend_on() should respect the current
        namespace scope and any 'use ...' statements. One exception is
        providing a function name from inside a class definition. In this case,
        we should automatically fallback to the current class, but prefixing
        the name with '::' should apply normal name resolution rules.

    -   Eliminate the ability to depend on the outcome of a specific run and
        instead "just do the right thing." Specifically: if a test depends on
        another test in the same run group, then the dependency will be
        satisfied if the requisite has passed the current run. Otherwise the
        dependency will be satisfied if the requisite has completed and passed
        all runs associated with the closest parent run. If this should be one
        test, then we can return state if the requisite saved any, otherwise
        this will just be a straight up "pass/fail" dependency with no
        returnable state.

    -   Instead of only allowing one 'setup_runs' function, allow for the
        definition of multiple 'setup_runXXXX' functions. The run name can then
        be derived from the function name (i.e., 'XXXX', possibly ignoring any
        leading underscore). This will make runs discoverable before actually
        executing them. There should then only ever be a 'teardown_runXXXX'
        function if there's an associated setup_run function.

-   Test parameterization

    -   Test validation of argument lists returned by directory setup

    -   Test teardown_run for directories, including handling of multiple
        teardown_run functions

    -   Test setup_run for files, including handling of multiple setup_run
        functions

    -   Test setup_run for directories, including handing of multiple
        setup_run functions

    -   Setup functions that are generators do not execute when called, but
        when iterated. This mean generator functions that have output escape
        our output buffering. We need to buffer both each iteration and the
        conversion of an iterator to an array in run_test().

-   Test that we don't skip any tokens when parsing files. In many cases,
    whitespace is optional, so an off-by-one error when iterating through the
    tokens means we could potentially miss a definition.

-   Remove the Context::assertX() methods and instead go back to one subtest()
    method. This means there will be one uniform way to run subtests.


Future / Wishlist
-----------------
-   Improve diff algorithm
    -   "a high-performance library in multiple languages that manipulates
        plain text"
        https://github.com/google/diff-match-patch

    -   "Utility to do an N-way diff and N-way merge, for N > 2"
        https://github.com/Quuxplusone/difdef

    -   Limit number of lines that are reported before and after the differing
        portion of text?

-   Support calling assert() with arbitrary exceptions in PHP >= 7? It's not
    entirely clear what this would even entail: perhaps allow treating custom
    exceptions as failures instead of errors?

-   Allow targeting of a specific parameterized test run?

-   Allow test functions and function fixtures to be moved into a class and
    "just work"?

-   Support "higher-level" dependencies, i.e., declaring a dependency on an
    entire class, file, or directory, all of whose tests must pass in order
    for the dependency to be satisfied. This probably means we want setup
    fixtures to be able to declare dependencies (and retrieve state), and
    teardown fixtures to be able to set state.
